{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergio-qp/AP_2_SQ_AG/blob/master/Proyect_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tX9VgN1lJq2V"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qgmI1o4vAX-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f9ad65a6-fd34-49ea-b7b9-a4ac584066da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ccdc4555-9fba-448b-a291-6df06ab8b6d3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ccdc4555-9fba-448b-a291-6df06ab8b6d3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving attrition_availabledata_02.csv to attrition_availabledata_02 (3).csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "uploaded=files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z7tc1Hjl-OwF",
        "outputId": "5b53a20b-eacc-47c2-9b5d-543dd12ac90e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         hrs  absences  JobInvolvement  PerformanceRating  \\\n",
            "0  10.060048       6.0             3.0                4.0   \n",
            "1   9.437671       2.0             2.0                3.0   \n",
            "2   7.900932      20.0             3.0                4.0   \n",
            "3   7.193853      19.0             4.0                3.0   \n",
            "4   6.979201       8.0             3.0                3.0   \n",
            "\n",
            "   EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance   Age  \\\n",
            "0                      2.0              4.0              1.0  31.0   \n",
            "1                      3.0              4.0              3.0  33.0   \n",
            "2                      3.0              4.0              3.0  35.0   \n",
            "3                      4.0              2.0              3.0  28.0   \n",
            "4                      2.0              4.0              2.0  31.0   \n",
            "\n",
            "      BusinessTravel              Department  ...  Over18  PercentSalaryHike  \\\n",
            "0  Travel_Frequently  Research & Development  ...       Y               23.0   \n",
            "1         Non-Travel  Research & Development  ...       Y               13.0   \n",
            "2      Travel_Rarely  Research & Development  ...       Y               22.0   \n",
            "3      Travel_Rarely  Research & Development  ...       Y               15.0   \n",
            "4      Travel_Rarely  Research & Development  ...       Y               12.0   \n",
            "\n",
            "  StandardHours  StockOptionLevel  TotalWorkingYears TrainingTimesLastYear  \\\n",
            "0           8.0               1.0                7.0                   5.0   \n",
            "1           8.0               0.0                7.0                   6.0   \n",
            "2           8.0               1.0               10.0                   4.0   \n",
            "3           8.0               0.0                1.0                   1.0   \n",
            "4           8.0               1.0               10.0                   2.0   \n",
            "\n",
            "   YearsAtCompany YearsSinceLastPromotion YearsWithCurrManager  Attrition  \n",
            "0             2.0                     2.0                  2.0        Yes  \n",
            "1             6.0                     1.0                  2.0         No  \n",
            "2            10.0                     7.0                  7.0        Yes  \n",
            "3             1.0                     0.0                  0.0         No  \n",
            "4             8.0                     7.0                  7.0         No  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "q_dnEXuqC5jN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f3df71-fd05-4782-e8fd-d0094f7f9252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows: 2940\n",
            "Number of Columns: 28\n",
            "Column Types: {'float64': 21, 'object': 7}\n",
            "Categorical Variables: ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Attrition']\n",
            "Numerical Variables: ['hrs', 'absences', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age', 'DistanceFromHome', 'Education', 'EmployeeID', 'JobLevel', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
            "Categorical Cardinality: {'BusinessTravel': 3, 'Department': 3, 'EducationField': 6, 'Gender': 2, 'JobRole': 9, 'MaritalStatus': 3, 'Attrition': 2}\n",
            "Missing Values: There are not missing values\n",
            "Constant Columns: []\n",
            "Possible ID Columns: ['EmployeeID']\n",
            "Problem Type: classification\n",
            "Class Distribution (if classification): Attrition\n",
            "No     0.838776\n",
            "Yes    0.161224\n",
            "Name: count, dtype: float64\n",
            "Is Imbalanced: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Información general\n",
        "num_rows = len(data)  # Número de filas\n",
        "num_columns = len(data.columns)  # Número de columnas\n",
        "\n",
        "# Tipos de columnas\n",
        "column_types = data.dtypes  # Tipos de datos de las columnas\n",
        "column_info = {}\n",
        "for dtype in column_types.unique():\n",
        "    column_info[str(dtype)] = sum(column_types == dtype)\n",
        "\n",
        "# Identificar variables categóricas y numéricas\n",
        "categorical_vars = [col for col in data.columns if data[col].dtype == 'object']\n",
        "numerical_vars = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Cardinalidad de las variables categóricas\n",
        "categorical_cardinality = {}\n",
        "for col in categorical_vars:\n",
        "    categorical_cardinality[col] = data[col].nunique()\n",
        "\n",
        "# Valores faltantes\n",
        "\n",
        "if data[col].isnull().sum().sum()>0:\n",
        "    missing_values=\"There are missing values\"\n",
        "\n",
        "else:\n",
        "  missing_values=\"There are not missing values\"\n",
        "\n",
        "# Columnas constantes\n",
        "constant_columns = [col for col in data.columns if data[col].nunique() == 1]\n",
        "\n",
        "\n",
        "# Columnas de ID\n",
        "possible_id_columns = []\n",
        "for col in data.columns:\n",
        "    if data[col].nunique() == num_rows:\n",
        "        possible_id_columns.append(col)\n",
        "\n",
        "# Tipo de problema (regresión o clasificación)\n",
        "target_variable = data.columns[-1]  # Última columna como objetivo\n",
        "if data[target_variable].nunique() <= 10:\n",
        "    target_type = 'classification'\n",
        "else:\n",
        "    target_type = 'regression'\n",
        "\n",
        "# Distribución de clases (si es clasificación)\n",
        "if target_type == 'classification':\n",
        "    class_counts = data[target_variable].value_counts()  # Cuenta cada clase\n",
        "    total_counts = len(data[target_variable])  # Total de filas\n",
        "    class_distribution = class_counts / total_counts  # Proporción de cada clase\n",
        "\n",
        "    # Verifica si el dataset está desbalanceado\n",
        "    is_imbalanced = class_distribution.max() > 0.6  # Usa .max() con paréntesis\n",
        "else:\n",
        "    class_distribution = None\n",
        "    is_imbalanced = None\n",
        "\n",
        "# Resumen del EDA\n",
        "eda_summary = {\n",
        "    \"Number of Rows\": num_rows,\n",
        "    \"Number of Columns\": num_columns,\n",
        "    \"Column Types\": column_info,\n",
        "    \"Categorical Variables\": categorical_vars,\n",
        "    \"Numerical Variables\": numerical_vars,\n",
        "    \"Categorical Cardinality\": categorical_cardinality,\n",
        "    \"Missing Values\": missing_values,\n",
        "    \"Constant Columns\": constant_columns,\n",
        "    \"Possible ID Columns\": possible_id_columns,\n",
        "    \"Problem Type\": target_type,\n",
        "    \"Class Distribution (if classification)\": class_distribution,\n",
        "    \"Is Imbalanced\": is_imbalanced,\n",
        "}\n",
        "\n",
        "\n",
        "for key, value in eda_summary.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 2940 rows and 31 columns. Of these 31 variables, 23 are numerical variables, and 8 are categorical variables. These categorical variables include: BusinessTravel, Department, or Gender. They have different values; for example, Gender has two unique values: \"Female\" and \"Male.\" On the other hand, there are other categorical variables, such as JobRole, which have 9 unique values, indicating different roles like Sales Executive or Manager.\n",
        "\n",
        "Before performing any statistical analysis, it is crucial to check if the dataset contains missing values, as they can cause errors. As observed, the dataset does not have any missing values. Similarly, it is essential to verify if there are variables that have the same value across all observations, as these variables could be removed. In this dataset, Over18, EmployeeCount, and StandardHours are constant variables, which do not provide any useful information and should be eliminated.\n",
        "\n",
        "To determine whether we have a classification or regression problem, it is necessary to identify our target variable. The target variable is Attrition, whose unique values are \"Yes\" and \"No.\" Therefore, as it is a categorical variable, this is a classification problem.\n",
        "\n",
        "The target variable presents significant imbalance, with 83% of the observations corresponding to employees who do not leave (\"No\") and 16% belonging to the \"Yes\" category."
      ],
      "metadata": {
        "id": "7PdAQKikygqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove constant columns from the DataFrame\n",
        "data = data.drop(columns=constant_columns)\n",
        "\n",
        "# Display the removed columns\n",
        "print(f\"Constant Columns Removed: {constant_columns}\")\n",
        "\n",
        "# Update and display the new number of rows and columns\n",
        "num_rows = len(data)\n",
        "num_columns = len(data.columns)\n",
        "\n",
        "print(f\"Updated DataFrame: {num_rows} rows and {num_columns} columns.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvbZWKruEmjM",
        "outputId": "d6b410db-70f1-4e3d-974d-314d24043f92"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant Columns Removed: []\n",
            "Updated DataFrame: 2940 rows and 28 columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SET UP\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(columns=['Attrition'])  # Drop target variable\n",
        "y = data['Attrition'].replace({'No': 0, 'Yes': 1})\n",
        "# Division de los datos\n",
        "# Split the dataset into training and testing sets (80/20 split)\n",
        "seed = 123456  # Set a fixed seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofduxB81GLVa",
        "outputId": "08574120-9698-4d86-bd87-8a2c0c132bd0"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-125a3e86c9fa>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = data['Attrition'].replace({'No': 0, 'Yes': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Holdout method involves splitting the dataset into training and test sets. In this case, 80% of the observations were assigned to the training set, and 20% to the test set.\n",
        "\n",
        "Holdout was used because it simulates the model's effectiveness on completely new data. Additionally, since the target variable is imbalanced, it is essential to maintain the proportion of classes in both samples to ensure that one sample does not contain only one class of the target variable."
      ],
      "metadata": {
        "id": "2g3aXDZyQlW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Identify categorical and numerical columns\n",
        "# This separates the features into categorical and numerical types for preprocessing.\n",
        "categorical_vars = X.select_dtypes(include=['object']).columns.tolist()  # List of categorical columns\n",
        "numerical_vars = X.select_dtypes(include=['int64', 'float64']).columns.tolist()  # List of numerical columns\n",
        "\n",
        "# Step 2: Create a preprocessor\n",
        "# A ColumnTransformer is used to apply different transformations to categorical and numerical columns.\n",
        "# - Categorical: OneHotEncoder to convert categories into binary columns.\n",
        "# - Numerical: 'passthrough' means numerical columns are not transformed.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_vars),  # Transform categorical variables\n",
        "        ('num', 'passthrough', numerical_vars)  # Keep numerical variables as is\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Method 1: Dummy Classifier (Baseline)\n",
        "# A simple classifier that always predicts the most frequent class. This is used as a baseline for comparison.\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=42)  # Most frequent strategy\n",
        "dummy_clf.fit(X_train, y_train)  # Train on the training data\n",
        "dummy_preds = dummy_clf.predict(X_test)  # Predict on the test data\n",
        "dummy_acc = accuracy_score(y_test, dummy_preds)  # Calculate accuracy\n",
        "dummy_bal_acc = balanced_accuracy_score(y_test, dummy_preds)  # Calculate balanced accuracy\n",
        "\n",
        "# Method 2: Decision Tree with Pipeline\n",
        "# Combines the preprocessor and a Decision Tree model into a single pipeline for clean and efficient workflow.\n",
        "tree_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing to the data\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))  # Train a Decision Tree classifier\n",
        "])\n",
        "tree_pipeline.fit(X_train, y_train)  # Train the pipeline\n",
        "tree_preds = tree_pipeline.predict(X_test)  # Predict using the trained pipeline\n",
        "tree_acc = accuracy_score(y_test, tree_preds)  # Calculate accuracy\n",
        "tree_bal_acc = balanced_accuracy_score(y_test, tree_preds)  # Calculate balanced accuracy\n",
        "\n",
        "# Method 3: KNN with StandardScaler\n",
        "# Combines preprocessing, scaling (StandardScaler), and KNN model into a single pipeline.\n",
        "knn_pipeline_std = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing\n",
        "    ('scaler', StandardScaler()),  # Scale features to have mean=0 and std=1\n",
        "    ('classifier', KNeighborsClassifier())  # Train a KNN classifier\n",
        "])\n",
        "knn_pipeline_std.fit(X_train, y_train)  # Train the pipeline\n",
        "knn_std_preds = knn_pipeline_std.predict(X_test)  # Predict using the trained pipeline\n",
        "knn_std_acc = accuracy_score(y_test, knn_std_preds)  # Calculate accuracy\n",
        "knn_std_bal_acc = balanced_accuracy_score(y_test, knn_std_preds)  # Calculate balanced accuracy\n",
        "\n",
        "# Method 4: KNN with MinMaxScaler\n",
        "# Similar to the StandardScaler pipeline, but uses MinMaxScaler for scaling.\n",
        "knn_pipeline_minmax = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing\n",
        "    ('scaler', MinMaxScaler()),  # Scale features to range [0, 1]\n",
        "    ('classifier', KNeighborsClassifier())  # Train a KNN classifier\n",
        "])\n",
        "knn_pipeline_minmax.fit(X_train, y_train)  # Train the pipeline\n",
        "knn_minmax_preds = knn_pipeline_minmax.predict(X_test)  # Predict using the trained pipeline\n",
        "knn_minmax_acc = accuracy_score(y_test, knn_minmax_preds)  # Calculate accuracy\n",
        "knn_minmax_bal_acc = balanced_accuracy_score(y_test, knn_minmax_preds)  # Calculate balanced accuracy\n",
        "\n",
        "# Step 5: Display results\n",
        "# Print the performance metrics (Accuracy and Balanced Accuracy) for all models.\n",
        "print(\"Results:\")\n",
        "print(f\"Dummy Classifier - Accuracy: {dummy_acc:.2f}, Balanced Accuracy: {dummy_bal_acc:.2f}\")\n",
        "print(f\"Decision Tree - Accuracy: {tree_acc:.2f}, Balanced Accuracy: {tree_bal_acc:.2f}\")\n",
        "print(f\"KNN (StandardScaler) - Accuracy: {knn_std_acc:.2f}, Balanced Accuracy: {knn_std_bal_acc:.2f}\")\n",
        "print(f\"KNN (MinMaxScaler) - Accuracy: {knn_minmax_acc:.2f}, Balanced Accuracy: {knn_minmax_bal_acc:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IN048_cfW3w",
        "outputId": "0eebdb5a-d3fa-4950-c7e7-c34cce6f4de1"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "Dummy Classifier - Accuracy: 0.84, Balanced Accuracy: 0.50\n",
            "Decision Tree - Accuracy: 0.92, Balanced Accuracy: 0.84\n",
            "KNN (StandardScaler) - Accuracy: 0.86, Balanced Accuracy: 0.66\n",
            "KNN (MinMaxScaler) - Accuracy: 0.86, Balanced Accuracy: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this section, the following procedures were carried out:\n",
        "\n",
        "Identification of categorical and numerical columns: As performed in the EDA section, categorical and numerical variables were identified.\n",
        "Transformation of categorical variables: Categorical variables were converted into binary variables using OneHotEncoder.\n",
        "Dummy Classifier: This model predicts the most frequent class in the dataset.\n",
        "Decision Tree and KNN: A Decision Tree model was implemented, as well as KNN, which compares distances between data points. For KNN, the scales of variables can significantly impact the model's performance. Therefore, two types of scaling methods were compared: StandardScaler and MinMaxScaler.\n",
        "Evaluation of classification methods: The effectiveness of the various classification methods was calculated and compared.\n"
      ],
      "metadata": {
        "id": "21FJ8sL5heoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paso 1: Identificar variables categóricas y numéricas\n",
        "categorical_vars = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_vars = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Paso 2: Crear un preprocesador\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_vars),  # Codificar categóricas\n",
        "        ('num', 'passthrough', numerical_vars)  # Mantener numéricas\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Paso 3: Pipeline para Decision Tree\n",
        "tree_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Preprocesamiento\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))  # Modelo\n",
        "])\n",
        "\n",
        "# Entrenar Decision Tree\n",
        "tree_pipeline.fit(X_train, y_train)\n",
        "tree_preds = tree_pipeline.predict(X_test)\n",
        "tree_acc = accuracy_score(y_test, tree_preds)\n",
        "print(f\"Decision Tree Accuracy: {tree_acc:.2f}\")\n",
        "\n",
        "# Paso 4: Pipeline para KNN con StandardScaler\n",
        "knn_pipeline_std = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Preprocesamiento\n",
        "    ('scaler', StandardScaler()),  # Escalado estándar\n",
        "    ('classifier', KNeighborsClassifier())  # Modelo KNN\n",
        "])\n",
        "\n",
        "# Entrenar KNN con StandardScaler\n",
        "knn_pipeline_std.fit(X_train, y_train)\n",
        "knn_std_preds = knn_pipeline_std.predict(X_test)\n",
        "knn_std_acc = accuracy_score(y_test, knn_std_preds)\n",
        "print(f\"KNN (StandardScaler) Accuracy: {knn_std_acc:.2f}\")\n",
        "\n",
        "# Paso 5: Pipeline para KNN con MinMaxScaler\n",
        "knn_pipeline_minmax = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Preprocesamiento\n",
        "    ('scaler', MinMaxScaler()),  # Escalado Min-Max\n",
        "    ('classifier', KNeighborsClassifier())  # Modelo KNN\n",
        "])\n",
        "\n",
        "# Entrenar KNN con MinMaxScaler\n",
        "knn_pipeline_minmax.fit(X_train, y_train)\n",
        "knn_minmax_preds = knn_pipeline_minmax.predict(X_test)\n",
        "knn_minmax_acc = accuracy_score(y_test, knn_minmax_preds)\n",
        "print(f\"KNN (MinMaxScaler) Accuracy: {knn_minmax_acc:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np_60ykLaa6U",
        "outputId": "7d0bef5b-4405-4f80-bfe7-0f1a31b8b6ca"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.92\n",
            "KNN (StandardScaler) Accuracy: 0.86\n",
            "KNN (MinMaxScaler) Accuracy: 0.86\n",
            "Best Parameters for Decision Tree: {'classifier__max_depth': 13, 'classifier__min_samples_split': 2}\n",
            "Best Cross-Validated Accuracy for Decision Tree: 0.87\n",
            "Best Parameters for KNN (StandardScaler): {'classifier__n_neighbors': 1}\n",
            "Best Cross-Validated Accuracy for KNN (StandardScaler): 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner evaluation with 3-fold cross-validation\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)"
      ],
      "metadata": {
        "id": "dEMagnS4XA3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlIJbVnkFWKr2/dh63Y2XR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}