{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergio-qp/AP_2_SQ_AG/blob/master/Proyect_2_Draft%2003_01_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tX9VgN1lJq2V"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qgmI1o4vAX-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "82291ae2-0cef-433e-e0df-bf0a46047f67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96c9f0b6-f62f-4693-a3dc-c1e72d1dc25e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96c9f0b6-f62f-4693-a3dc-c1e72d1dc25e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving attrition_availabledata_02.csv to attrition_availabledata_02.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "uploaded=files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z7tc1Hjl-OwF",
        "outputId": "608670ca-99e7-4312-90ce-ca049fad0d8c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         hrs  absences  JobInvolvement  PerformanceRating  \\\n",
            "0  10.060048       6.0             3.0                4.0   \n",
            "1   9.437671       2.0             2.0                3.0   \n",
            "2   7.900932      20.0             3.0                4.0   \n",
            "3   7.193853      19.0             4.0                3.0   \n",
            "4   6.979201       8.0             3.0                3.0   \n",
            "\n",
            "   EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance   Age  \\\n",
            "0                      2.0              4.0              1.0  31.0   \n",
            "1                      3.0              4.0              3.0  33.0   \n",
            "2                      3.0              4.0              3.0  35.0   \n",
            "3                      4.0              2.0              3.0  28.0   \n",
            "4                      2.0              4.0              2.0  31.0   \n",
            "\n",
            "      BusinessTravel              Department  ...  MonthlyIncome  \\\n",
            "0  Travel_Frequently  Research & Development  ...        65000.0   \n",
            "1         Non-Travel  Research & Development  ...        63850.0   \n",
            "2      Travel_Rarely  Research & Development  ...        19040.0   \n",
            "3      Travel_Rarely  Research & Development  ...        52100.0   \n",
            "4      Travel_Rarely  Research & Development  ...        29360.0   \n",
            "\n",
            "   NumCompaniesWorked PercentSalaryHike  StockOptionLevel TotalWorkingYears  \\\n",
            "0                 6.0              23.0               1.0               7.0   \n",
            "1                 1.0              13.0               0.0               7.0   \n",
            "2                 1.0              22.0               1.0              10.0   \n",
            "3                 1.0              15.0               0.0               1.0   \n",
            "4                 4.0              12.0               1.0              10.0   \n",
            "\n",
            "   TrainingTimesLastYear YearsAtCompany YearsSinceLastPromotion  \\\n",
            "0                    5.0            2.0                     2.0   \n",
            "1                    6.0            6.0                     1.0   \n",
            "2                    4.0           10.0                     7.0   \n",
            "3                    1.0            1.0                     0.0   \n",
            "4                    2.0            8.0                     7.0   \n",
            "\n",
            "   YearsWithCurrManager  Attrition  \n",
            "0                   2.0        Yes  \n",
            "1                   2.0         No  \n",
            "2                   7.0        Yes  \n",
            "3                   0.0         No  \n",
            "4                   7.0         No  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "q_dnEXuqC5jN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4024be-9f9c-4977-add5-6f9a00784299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant Columns Removed: []\n",
            "Number of Rows: 2940\n",
            "Number of Columns: 28\n",
            "Column Types: {'float64': 21, 'object': 7}\n",
            "Categorical Variables: ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Attrition']\n",
            "Numerical Variables: ['hrs', 'absences', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age', 'DistanceFromHome', 'Education', 'EmployeeID', 'JobLevel', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
            "Categorical Variables Table:          Variable  Cardinality\n",
            "0  BusinessTravel            3\n",
            "1      Department            3\n",
            "2  EducationField            6\n",
            "3          Gender            2\n",
            "4         JobRole            9\n",
            "5   MaritalStatus            3\n",
            "6       Attrition            2\n",
            "Missing Values: There are no missing values\n",
            "Removed Constant Columns: []\n",
            "Possible ID Columns: ['EmployeeID']\n",
            "Problem Type: classification\n",
            "Class Distribution (if classification): Attrition\n",
            "No     0.838776\n",
            "Yes    0.161224\n",
            "Name: count, dtype: float64\n",
            "Is Imbalanced: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# General Information\n",
        "num_rows = len(data)  # Number of rows\n",
        "num_columns = len(data.columns)  # Number of columns\n",
        "\n",
        "# Column Types\n",
        "column_types = data.dtypes  # Data types of the columns\n",
        "column_info = {}\n",
        "for dtype in column_types.unique():\n",
        "    column_info[str(dtype)] = sum(column_types == dtype)\n",
        "\n",
        "# Identify categorical and numerical variables\n",
        "categorical_vars = [col for col in data.columns if data[col].dtype == 'object']\n",
        "numerical_vars = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Cardinality of categorical variables\n",
        "categorical_cardinality = {}\n",
        "for col in categorical_vars:\n",
        "    categorical_cardinality[col] = data[col].nunique()\n",
        "\n",
        "# Missing Values\n",
        "if data.isnull().sum().sum() > 0:\n",
        "    missing_values = \"There are missing values\"\n",
        "else:\n",
        "    missing_values = \"There are no missing values\"\n",
        "\n",
        "# Constant Columns\n",
        "constant_columns = [col for col in data.columns if data[col].nunique() == 1]\n",
        "print(f\"Constant Columns Removed: {constant_columns}\")\n",
        "\n",
        "# ID Columns\n",
        "possible_id_columns = []\n",
        "for col in data.columns:\n",
        "    if data[col].nunique() == num_rows:\n",
        "        possible_id_columns.append(col)\n",
        "\n",
        "# Problem Type (Regression or Classification)\n",
        "target_variable = data.columns[-1]  # Last column as target\n",
        "if data[target_variable].nunique() <= 10:\n",
        "    target_type = 'classification'\n",
        "else:\n",
        "    target_type = 'regression'\n",
        "\n",
        "# Class Distribution (if classification)\n",
        "if target_type == 'classification':\n",
        "    class_counts = data[target_variable].value_counts()  # Count each class\n",
        "    total_counts = len(data[target_variable])  # Total rows\n",
        "    class_distribution = class_counts / total_counts  # Proportion of each class\n",
        "\n",
        "    # Check if the dataset is imbalanced\n",
        "    is_imbalanced = class_distribution.max() > 0.6  # Use .max() with parentheses\n",
        "else:\n",
        "    class_distribution = None\n",
        "    is_imbalanced = None\n",
        "\n",
        "# EDA Summary\n",
        "eda_summary = {\n",
        "    \"Number of Rows\": num_rows,\n",
        "    \"Number of Columns\": num_columns,\n",
        "    \"Column Types\": column_info,\n",
        "    \"Categorical Variables\": categorical_vars,\n",
        "    \"Numerical Variables\": numerical_vars,\n",
        "    \"Categorical Variables Table\": pd.DataFrame({\n",
        "        \"Variable\": categorical_vars,\n",
        "        \"Cardinality\": [categorical_cardinality[col] for col in categorical_vars]\n",
        "    }),\n",
        "    \"Missing Values\": missing_values,\n",
        "    \"Removed Constant Columns\": constant_columns,\n",
        "    \"Possible ID Columns\": possible_id_columns,\n",
        "    \"Problem Type\": target_type,\n",
        "    \"Class Distribution (if classification)\": class_distribution,\n",
        "    \"Is Imbalanced\": is_imbalanced,\n",
        "}\n",
        "\n",
        "for key, value in eda_summary.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 2940 rows and 31 columns. Of these 31 variables, 23 are numerical variables, and 8 are categorical variables. These categorical variables include: BusinessTravel, Department, or Gender. They have different values; for example, Gender has two unique values: \"Female\" and \"Male.\" On the other hand, there are other categorical variables, such as JobRole, which have 9 unique values, indicating different roles like Sales Executive or Manager.\n",
        "\n",
        "Before performing any statistical analysis, it is crucial to check if the dataset contains missing values, as they can cause errors. As observed, the dataset does not have any missing values. Similarly, it is essential to verify if there are variables that have the same value across all observations, as these variables could be removed. In this dataset, Over18, EmployeeCount, and StandardHours are constant variables, which do not provide any useful information and should be eliminated.\n",
        "\n",
        "To determine whether we have a classification or regression problem, it is necessary to identify our target variable. The target variable is Attrition, whose unique values are \"Yes\" and \"No.\" Therefore, as it is a categorical variable, this is a classification problem.\n",
        "\n",
        "The target variable presents significant imbalance, with 83% of the observations corresponding to employees who do not leave (\"No\") and 16% belonging to the \"Yes\" category."
      ],
      "metadata": {
        "id": "7PdAQKikygqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove constant columns from the DataFrame\n",
        "data = data.drop(columns=constant_columns)\n",
        "\n",
        "# Display the removed columns\n",
        "print(f\"Constant Columns Removed: {constant_columns}\")\n",
        "\n",
        "# Update and display the new number of rows and columns\n",
        "num_rows = len(data)\n",
        "num_columns = len(data.columns)\n",
        "\n",
        "print(f\"Updated DataFrame: {num_rows} rows and {num_columns} columns.\")\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvbZWKruEmjM",
        "outputId": "1df60854-bb71-4e35-9fba-4d6b7ff75223"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant Columns Removed: []\n",
            "Updated DataFrame: 2940 rows and 28 columns.\n",
            "         hrs  absences  JobInvolvement  PerformanceRating  \\\n",
            "0  10.060048       6.0             3.0                4.0   \n",
            "1   9.437671       2.0             2.0                3.0   \n",
            "2   7.900932      20.0             3.0                4.0   \n",
            "3   7.193853      19.0             4.0                3.0   \n",
            "4   6.979201       8.0             3.0                3.0   \n",
            "\n",
            "   EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance   Age  \\\n",
            "0                      2.0              4.0              1.0  31.0   \n",
            "1                      3.0              4.0              3.0  33.0   \n",
            "2                      3.0              4.0              3.0  35.0   \n",
            "3                      4.0              2.0              3.0  28.0   \n",
            "4                      2.0              4.0              2.0  31.0   \n",
            "\n",
            "      BusinessTravel              Department  ...  MonthlyIncome  \\\n",
            "0  Travel_Frequently  Research & Development  ...        65000.0   \n",
            "1         Non-Travel  Research & Development  ...        63850.0   \n",
            "2      Travel_Rarely  Research & Development  ...        19040.0   \n",
            "3      Travel_Rarely  Research & Development  ...        52100.0   \n",
            "4      Travel_Rarely  Research & Development  ...        29360.0   \n",
            "\n",
            "   NumCompaniesWorked PercentSalaryHike  StockOptionLevel TotalWorkingYears  \\\n",
            "0                 6.0              23.0               1.0               7.0   \n",
            "1                 1.0              13.0               0.0               7.0   \n",
            "2                 1.0              22.0               1.0              10.0   \n",
            "3                 1.0              15.0               0.0               1.0   \n",
            "4                 4.0              12.0               1.0              10.0   \n",
            "\n",
            "   TrainingTimesLastYear YearsAtCompany YearsSinceLastPromotion  \\\n",
            "0                    5.0            2.0                     2.0   \n",
            "1                    6.0            6.0                     1.0   \n",
            "2                    4.0           10.0                     7.0   \n",
            "3                    1.0            1.0                     0.0   \n",
            "4                    2.0            8.0                     7.0   \n",
            "\n",
            "   YearsWithCurrManager  Attrition  \n",
            "0                   2.0        Yes  \n",
            "1                   2.0         No  \n",
            "2                   7.0        Yes  \n",
            "3                   0.0         No  \n",
            "4                   7.0         No  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SET UP\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(columns=['Attrition'])  # Drop target variable\n",
        "y = data['Attrition'].replace({'No': 0, 'Yes': 1})\n",
        "print(y.value_counts())\n",
        "\n",
        "# Division de los datos\n",
        "# Split the dataset into training and testing sets (80/20 split)\n",
        "seed = 123456  # Set a fixed seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofduxB81GLVa",
        "outputId": "230e69a8-46c7-4535-f84d-c0896503c81f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attrition\n",
            "0    2466\n",
            "1     474\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-27ca964790e0>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = data['Attrition'].replace({'No': 0, 'Yes': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Holdout method involves splitting the dataset into training and test sets. In this case, 80% of the observations were assigned to the training set, and 20% to the test set.\n",
        "\n",
        "Holdout was used because it simulates the model's effectiveness on completely new data. Additionally, since the target variable is imbalanced, it is essential to maintain the proportion of classes in both samples to ensure that one sample does not contain only one class of the target variable."
      ],
      "metadata": {
        "id": "2g3aXDZyQlW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Identify categorical and numerical columns\n",
        "# This separates the features into categorical and numerical types for preprocessing.\n",
        "categorical_vars = X.select_dtypes(include=['object']).columns.tolist()  # List of categorical columns\n",
        "numerical_vars = X.select_dtypes(include=['int64', 'float64']).columns.tolist()  # List of numerical columns\n",
        "\n",
        "# Step 2: Create a preprocessor\n",
        "# A ColumnTransformer is used to apply different transformations to categorical and numerical columns.\n",
        "# - Categorical: OneHotEncoder to convert categories into binary columns.\n",
        "# - Numerical: 'passthrough' means numerical columns are not transformed.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_vars),  # Transform categorical variables\n",
        "        ('num', 'passthrough', numerical_vars)  # Keep numerical variables as is\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Method 1: Dummy Classifier (Baseline)\n",
        "# A simple classifier that always predicts the most frequent class. This is used as a baseline for comparison.\n",
        "start_dummy = time.time()  # Start timing\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=42)  # Most frequent strategy\n",
        "dummy_clf.fit(X_train, y_train)  # Train on the training data\n",
        "dummy_preds = dummy_clf.predict(X_test)  # Predict on the test data\n",
        "dummy_acc = accuracy_score(y_test, dummy_preds)  # Calculate accuracy\n",
        "dummy_bal_acc = balanced_accuracy_score(y_test, dummy_preds)  # Calculate balanced accuracy\n",
        "dummy_time = time.time() - start_dummy  # End timing\n",
        "\n",
        "# Method 2: Decision Tree with Pipeline\n",
        "# Combines the preprocessor and a Decision Tree model into a single pipeline for clean and efficient workflow.\n",
        "start_tree = time.time()  # Start timing\n",
        "tree_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing to the data\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))  # Train a Decision Tree classifier\n",
        "])\n",
        "tree_pipeline.fit(X_train, y_train)  # Train the pipeline\n",
        "tree_preds = tree_pipeline.predict(X_test)  # Predict using the trained pipeline\n",
        "tree_acc = accuracy_score(y_test, tree_preds)  # Calculate accuracy\n",
        "tree_bal_acc = balanced_accuracy_score(y_test, tree_preds)  # Calculate balanced accuracy\n",
        "tree_time = time.time() - start_tree  # End timing\n",
        "\n",
        "# Method 3: KNN with StandardScaler\n",
        "# Combines preprocessing, scaling (StandardScaler), and KNN model into a single pipeline.\n",
        "start_knn_std = time.time()  # Start timing\n",
        "knn_pipeline_std = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing\n",
        "    ('scaler', StandardScaler()),  # Scale features to have mean=0 and std=1\n",
        "    ('classifier', KNeighborsClassifier())  # Train a KNN classifier\n",
        "])\n",
        "knn_pipeline_std.fit(X_train, y_train)  # Train the pipeline\n",
        "knn_std_preds = knn_pipeline_std.predict(X_test)  # Predict using the trained pipeline\n",
        "knn_std_acc = accuracy_score(y_test, knn_std_preds)  # Calculate accuracy\n",
        "knn_std_bal_acc = balanced_accuracy_score(y_test, knn_std_preds)  # Calculate balanced accuracy\n",
        "knn_std_time = time.time() - start_knn_std  # End timing\n",
        "\n",
        "# Method 4: KNN with MinMaxScaler\n",
        "# Similar to the StandardScaler pipeline, but uses MinMaxScaler for scaling.\n",
        "start_knn_minmax = time.time()  # Start timing\n",
        "knn_pipeline_minmax = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing\n",
        "    ('scaler', MinMaxScaler()),  # Scale features to range [0, 1]\n",
        "    ('classifier', KNeighborsClassifier())  # Train a KNN classifier\n",
        "])\n",
        "knn_pipeline_minmax.fit(X_train, y_train)  # Train the pipeline\n",
        "knn_minmax_preds = knn_pipeline_minmax.predict(X_test)  # Predict using the trained pipeline\n",
        "knn_minmax_acc = accuracy_score(y_test, knn_minmax_preds)  # Calculate accuracy\n",
        "knn_minmax_bal_acc = balanced_accuracy_score(y_test, knn_minmax_preds)  # Calculate balanced accuracy\n",
        "knn_minmax_time = time.time() - start_knn_minmax  # End timing\n",
        "\n",
        "# Step 5: Display results\n",
        "# Print the performance metrics (Accuracy and Balanced Accuracy) for all models.\n",
        "# Additionally, display the time taken for each model.\n",
        "print(\"Results:\")\n",
        "print(f\"Dummy Classifier - Accuracy: {dummy_acc:.2f}, Balanced Accuracy: {dummy_bal_acc:.2f}, Time: {dummy_time:.2f}s\")\n",
        "print(f\"Decision Tree - Accuracy: {tree_acc:.2f}, Balanced Accuracy: {tree_bal_acc:.2f}, Time: {tree_time:.2f}s\")\n",
        "print(f\"KNN (StandardScaler) - Accuracy: {knn_std_acc:.2f}, Balanced Accuracy: {knn_std_bal_acc:.2f}, Time: {knn_std_time:.2f}s\")\n",
        "print(f\"KNN (MinMaxScaler) - Accuracy: {knn_minmax_acc:.2f}, Balanced Accuracy: {knn_minmax_bal_acc:.2f}, Time: {knn_minmax_time:.2f}s\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IN048_cfW3w",
        "outputId": "336876ba-e686-44e0-b8e1-ac3307b0406f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "Dummy Classifier - Accuracy: 0.84, Balanced Accuracy: 0.50, Time: 0.01s\n",
            "Decision Tree - Accuracy: 0.92, Balanced Accuracy: 0.84, Time: 0.09s\n",
            "KNN (StandardScaler) - Accuracy: 0.86, Balanced Accuracy: 0.66, Time: 0.08s\n",
            "KNN (MinMaxScaler) - Accuracy: 0.86, Balanced Accuracy: 0.67, Time: 0.08s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this section, the following procedures were carried out:\n",
        "\n",
        "Identification of categorical and numerical columns: As performed in the EDA section, categorical and numerical variables were identified.\n",
        "Transformation of categorical variables: Categorical variables were converted into binary variables using OneHotEncoder.\n",
        "Dummy Classifier: This model predicts the most frequent class in the dataset.\n",
        "Decision Tree and KNN: A Decision Tree model was implemented, as well as KNN, which compares distances between data points. For KNN, the scales of variables can significantly impact the model's performance. Therefore, two types of scaling methods were compared: StandardScaler and MinMaxScaler.\n",
        "Evaluation of classification methods: The effectiveness of the various classification methods was calculated and compared.\n"
      ],
      "metadata": {
        "id": "21FJ8sL5heoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import time\n",
        "\n",
        "# Define parameters for Decision Tree\n",
        "tree_params = [\n",
        "    {'max_depth': 3, 'min_samples_split': 2},\n",
        "    {'max_depth': 5, 'min_samples_split': 5},\n",
        "    {'max_depth': 10, 'min_samples_split': 10},\n",
        "    {'max_depth': None, 'min_samples_split': 2}\n",
        "]\n",
        "\n",
        "best_tree_acc = 0\n",
        "best_tree_bal_acc = 0\n",
        "best_tree_params = None\n",
        "start_tree = time.time()\n",
        "\n",
        "for params in tree_params:\n",
        "    # Build pipeline for Decision Tree\n",
        "    tree_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),  # Use preprocessor from SET UP\n",
        "        ('model', DecisionTreeClassifier(random_state=42, **params))\n",
        "    ])\n",
        "\n",
        "    # Train and evaluate on holdout set\n",
        "    tree_pipeline.fit(X_train, y_train)\n",
        "    tree_preds = tree_pipeline.predict(X_test)\n",
        "    tree_acc = accuracy_score(y_test, tree_preds)\n",
        "    tree_bal_acc = balanced_accuracy_score(y_test, tree_preds)\n",
        "\n",
        "    # Update best parameters\n",
        "    if tree_acc > best_tree_acc:\n",
        "        best_tree_acc = tree_acc\n",
        "        best_tree_bal_acc = tree_bal_acc\n",
        "        best_tree_params = params\n",
        "\n",
        "tree_time = time.time() - start_tree\n",
        "\n",
        "\n",
        "# Define parameters for KNN\n",
        "knn_params = [\n",
        "    {'n_neighbors': 3, 'weights': 'uniform'},\n",
        "    {'n_neighbors': 5, 'weights': 'uniform'},\n",
        "    {'n_neighbors': 10, 'weights': 'distance'},\n",
        "    {'n_neighbors': 15, 'weights': 'distance'}\n",
        "]\n",
        "\n",
        "best_knn_acc = 0\n",
        "best_knn_bal_acc = 0\n",
        "best_knn_params = None\n",
        "start_knn = time.time()\n",
        "\n",
        "for params in knn_params:\n",
        "    # Build pipeline for KNN\n",
        "    knn_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),  # Use preprocessor\n",
        "        ('scaler', StandardScaler()),   # Scale features\n",
        "        ('model', KNeighborsClassifier(**params))\n",
        "    ])\n",
        "\n",
        "    # Train and evaluate on holdout set\n",
        "    knn_pipeline.fit(X_train, y_train)\n",
        "    knn_preds = knn_pipeline.predict(X_test)\n",
        "    knn_acc = accuracy_score(y_test, knn_preds)\n",
        "    knn_bal_acc = balanced_accuracy_score(y_test, knn_preds)\n",
        "\n",
        "    # Update best parameters\n",
        "    if knn_acc > best_knn_acc:\n",
        "        best_knn_acc = knn_acc\n",
        "        best_knn_bal_acc = knn_bal_acc\n",
        "        best_knn_params = params\n",
        "\n",
        "knn_time = time.time() - start_knn\n",
        "\n",
        "# Display results\n",
        "print(\"Hyperparameter Tuning Results:\")\n",
        "print(f\"Decision Tree - Best Params: {best_tree_params}, Accuracy: {best_tree_acc:.2f}, Balanced Accuracy: {best_tree_bal_acc:.2f}, Time: {tree_time:.2f}s\")\n",
        "print(f\"KNN - Best Params: {best_knn_params}, Accuracy: {best_knn_acc:.2f}, Balanced Accuracy: {best_knn_bal_acc:.2f}, Time: {knn_time:.2f}s\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzlr4TtBXmt5",
        "outputId": "0a77edb6-03d3-42ba-88b1-8301fc854c02"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter Tuning Results:\n",
            "Decision Tree - Best Params: {'max_depth': None, 'min_samples_split': 2}, Accuracy: 0.92, Balanced Accuracy: 0.84, Time: 0.26s\n",
            "KNN - Best Params: {'n_neighbors': 10, 'weights': 'distance'}, Accuracy: 0.91, Balanced Accuracy: 0.74, Time: 0.23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, hyperparameter optimization is performed for the KNN and decision tree models.\n",
        "\n",
        "Hyperparameters are \"configurations\" defined before applying a method to the training sample. The goal is to provide the best performance for each specified model.\n",
        "\n",
        "For decision trees, the best configuration was one with a depth of 5 levels, where a node is only split if there are at least 5 samples. This configuration achieved 92% accuracy and took around 45 seconds to test all combinations.\n",
        "\n",
        "For KNN, the best configuration considered the 10 closest neighbors, achieving 87% accuracy on the training group, which was lower than the decision tree's performance. It took at least 1 minute to test all combinations.\n"
      ],
      "metadata": {
        "id": "QGCx49x_dRnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = {\n",
        "    \"Method\": [\n",
        "        \"Dummy Classifier\",\n",
        "        \"Decision Tree\",\n",
        "        \"KNN (StandardScaler)\",\n",
        "        \"KNN (MinMaxScaler)\",\n",
        "        \"Decision Tree (Tuned)\",\n",
        "        \"KNN (Tuned)\"\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        dummy_acc,\n",
        "        tree_acc,\n",
        "        knn_std_acc,\n",
        "        knn_minmax_acc,\n",
        "        best_tree_acc,\n",
        "        best_knn_acc\n",
        "    ],\n",
        "    \"Balanced Accuracy\": [\n",
        "        dummy_bal_acc,\n",
        "        tree_bal_acc,\n",
        "        knn_std_bal_acc,\n",
        "        knn_minmax_bal_acc,\n",
        "        best_tree_bal_acc,\n",
        "        best_knn_bal_acc\n",
        "    ],\n",
        "    \"Time (s)\": [\n",
        "        dummy_time,\n",
        "        tree_time,\n",
        "        knn_std_time,\n",
        "        knn_minmax_time,\n",
        "        tree_time,\n",
        "        knn_time\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"Model Comparison Results:\")\n",
        "print(results_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-N8Vf-hX4OI",
        "outputId": "3dde972e-0e61-4abf-ac1f-da8d3e8a8273"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Comparison Results:\n",
            "                  Method  Accuracy  Balanced Accuracy  Time (s)\n",
            "0       Dummy Classifier  0.838435           0.500000  0.005822\n",
            "1          Decision Tree  0.916667           0.839831  0.263986\n",
            "2   KNN (StandardScaler)  0.860544           0.657649  0.077204\n",
            "3     KNN (MinMaxScaler)  0.855442           0.667353  0.075930\n",
            "4  Decision Tree (Tuned)  0.916667           0.839831  0.263986\n",
            "5            KNN (Tuned)  0.911565           0.743312  0.234926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8QpkC-EqgAAH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XI2NXsphf_kK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBeW4tOvSZ25FoTvU2ULzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}